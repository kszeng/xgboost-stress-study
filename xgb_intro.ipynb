{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/jk755/Desktop/Stress Study/Phase I Analyses/xgboost-stress-study/xgb_intro.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m diamonds \u001b[39m=\u001b[39m sns\u001b[39m.\u001b[39mload_dataset(\u001b[39m'\u001b[39m\u001b[39mdiamonds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.head()\n",
    "\n",
    "# in real-world datasets, need to explore, clean, and visualize the dataset first\n",
    "# here, 5-number summary of the numeric and categorial features built-in to seaborn\n",
    "diamonds.describe(exclude = np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build an XGBoost DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat       float64\n",
      "cut        category\n",
      "color      category\n",
      "clarity    category\n",
      "depth       float64\n",
      "table       float64\n",
      "x           float64\n",
      "y           float64\n",
      "z           float64\n",
      "dtype: object\n",
      "2.1.4\n",
      "BUILTIN_PREFETCH_PRESENT: True\n",
      "CLANG_VERSION: [15, 0, 0]\n",
      "DEBUG: False\n",
      "MM_PREFETCH_PRESENT: False\n",
      "USE_CUDA: False\n",
      "USE_DLOPEN_NCCL: False\n",
      "USE_FEDERATED: False\n",
      "USE_NCCL: False\n",
      "USE_OPENMP: True\n",
      "USE_RMM: False\n",
      "libxgboost: /Users/jk755/Library/Python/3.9/lib/python/site-packages/xgboost/lib/libxgboost.dylib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# goal: predict diamond prices using their physical measurements, so target will be the price column\n",
    "# candidate features are isolated into X and target labels into y\n",
    "\n",
    "# extract feature and target arrays\n",
    "X, y = diamonds.drop('price', axis=1), diamonds[['price']]\n",
    "\n",
    "# this dataset has three categorical columns. normally would encode with ordinal or one-hot encoding\n",
    "# XGBoost as the ability to internally deal with categoricals by casting to pandas \"category\" data type\n",
    "\n",
    "# extract text features\n",
    "cats = X.select_dtypes(exclude = np.number).columns.tolist()\n",
    "\n",
    "# convert to pandas category\n",
    "for col in cats:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# should get three category features when printing dtypes attribute:\n",
    "print(X.dtypes)\n",
    "\n",
    "# split the data into train and test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# create regression matrices\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n",
    "build_info = xgb.build_info()\n",
    "for name in sorted(build_info.keys()):\n",
    "    print(f'{name}: {build_info[name]}')\n",
    "\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical = True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python XGBoost Regression\n",
    "\n",
    "**After building the DMatrices, need to choose a value for the `objective` parameter. This tells XGBoost the machine learning problem to be solved and what metrics or loss functions to use to solve that problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The chosen objective function and any other hyperparameters of XGBoost should be specified in a dictionary, which by convention should be called params.\n",
    "\n",
    "Inside these initial `params`, also set `tree_method` to `gpu_hist`, which enables GPU acceleration. If no GPU, can omit the parameter or set it to `hist`.\n",
    "\n",
    "Then, set another parameter called `num_boost_round`, which stands for number of boosting rounds. Internally, XGBoost minimizes the loss function RMSE in small incremental rounds; this parameter specifies the number of those rounds.\n",
    "\n",
    "Ideal number of rounds is usually found through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[16:37:05] /Users/runner/work/xgboost/xgboost/src/gbm/../common/common.h:174: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000282820428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000002829ec3f8 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 1276\n  [bt] (2) 3   libxgboost.dylib                    0x0000000282a0b54c xgboost::LearnerConfiguration::Configure() + 1272\n  [bt] (3) 4   libxgboost.dylib                    0x0000000282a0b79c xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n  [bt] (4) 5   libxgboost.dylib                    0x0000000282842b34 XGBoosterUpdateOneIter + 144\n  [bt] (5) 6   libffi.dylib                        0x00000001a1a29050 ffi_call_SYSV + 80\n  [bt] (6) 7   libffi.dylib                        0x00000001a1a31af8 ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-39-darwin.so        0x00000001053733cc PyInit__ctypes + 25392\n  [bt] (8) 9   _ctypes.cpython-39-darwin.so        0x000000010536bed8 _ctypes.cpython-39-darwin.so + 16088\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/jk755/Desktop/Stress Study/Phase I Analyses/xgboost-stress-study/xgb_intro.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtree_method\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     params \u001b[39m=\u001b[39;49m params,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     dtrain \u001b[39m=\u001b[39;49m dtrain_reg, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     num_boost_round \u001b[39m=\u001b[39;49m n,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk755/Desktop/Stress%20Study/Phase%20I%20Analyses/xgboost-stress-study/xgb_intro.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:2100\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [16:37:05] /Users/runner/work/xgboost/xgboost/src/gbm/../common/common.h:174: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000282820428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x00000002829ec3f8 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 1276\n  [bt] (2) 3   libxgboost.dylib                    0x0000000282a0b54c xgboost::LearnerConfiguration::Configure() + 1272\n  [bt] (3) 4   libxgboost.dylib                    0x0000000282a0b79c xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n  [bt] (4) 5   libxgboost.dylib                    0x0000000282842b34 XGBoosterUpdateOneIter + 144\n  [bt] (5) 6   libffi.dylib                        0x00000001a1a29050 ffi_call_SYSV + 80\n  [bt] (6) 7   libffi.dylib                        0x00000001a1a31af8 ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-39-darwin.so        0x00000001053733cc PyInit__ctypes + 25392\n  [bt] (8) 9   _ctypes.cpython-39-darwin.so        0x000000010536bed8 _ctypes.cpython-39-darwin.so + 16088\n\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "params = {'objective': 'reg:squarederror', 'tree_method': 'gpu_hist'}\n",
    "\n",
    "n = 100 \n",
    "model = xgb.train(\n",
    "    params = params,\n",
    "    dtrain = dtrain_reg, \n",
    "    num_boost_round = n,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
